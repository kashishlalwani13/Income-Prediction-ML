{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn\n",
        "!pip install tensorflow tensorflow-gpu\n",
        "!pip install keras\n",
        "!pip install plotly\n",
        "!pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vdwk9Qx6eS5c",
        "outputId": "0fe78412-cc3e-4840-b15b-2184d4642566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m177.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m199.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m205.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "7d88b69c01634f61a6fd4606fddf9c7d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, f1_score\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_data(train_path, test_path):\n",
        "    # Load the preprocessed data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop('income', axis=1)\n",
        "    y_train = (train_data['income'] == '>50K').astype(int)  # Convert to binary (0 for <=50K, 1 for >50K)\n",
        "\n",
        "    X_test = test_data.drop('income', axis=1)\n",
        "    y_test = (test_data['income'] == '>50K').astype(int)\n",
        "\n",
        "    # Identify numeric and categorical columns\n",
        "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    print(f\"Numeric features: {numeric_features}\")\n",
        "    print(f\"Categorical features: {categorical_features}\")\n",
        "\n",
        "    # Create preprocessing pipelines\n",
        "    # For numeric features: standard scaling\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # For categorical features: one-hot encoding\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing steps\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Apply preprocessing\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "    # Get feature names after one-hot encoding\n",
        "    categorical_feature_names = []\n",
        "    if categorical_features:\n",
        "        categorical_feature_names = list(\n",
        "            preprocessor.named_transformers_['cat']['onehot']\n",
        "            .get_feature_names_out(categorical_features)\n",
        "        )\n",
        "\n",
        "    all_feature_names = numeric_features + categorical_feature_names\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(X_train_processed).to(device)\n",
        "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
        "    X_test_tensor = torch.FloatTensor(X_test_processed).to(device)\n",
        "    y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1).to(device)\n",
        "\n",
        "    print(f\"X_train shape after preprocessing: {X_train_processed.shape}\")\n",
        "    print(f\"X_test shape after preprocessing: {X_test_processed.shape}\")\n",
        "\n",
        "    return (X_train_processed, X_test_processed, y_train.values, y_test.values,\n",
        "            X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,\n",
        "            preprocessor, X_train_processed.shape[1])\n",
        "\n",
        "# Neural Network Model using PyTorch\n",
        "class IncomeNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(IncomeNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
        "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
        "        x = self.dropout(self.relu(self.bn3(self.fc3(x))))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# Function to train the PyTorch neural network\n",
        "def train_nn_model(X_train_tensor, y_train_tensor, X_test_tensor, input_size, batch_size=64, epochs=20):\n",
        "    # Create DataLoader for batching\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = IncomeNN(input_size).to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print statistics\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f'Training completed in {training_time:.2f} seconds')\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Make predictions\n",
        "        y_pred_proba = model(X_test_tensor)\n",
        "        y_pred = (y_pred_proba > 0.5).cpu().numpy().astype(int).flatten()\n",
        "\n",
        "    return model, y_pred, training_time\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(y_test, y_pred, model_name, training_time=None, pred_time=None):\n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Sensitivity (Recall for >50K class or 1)\n",
        "    sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "    # Specificity (Recall for <=50K class or 0)\n",
        "    specificity = recall_score(y_test, y_pred, pos_label=0)\n",
        "\n",
        "    # F1 score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\n--- {model_name} Results ---\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sensitivity (Recall for >50K): {sensitivity:.4f}\")\n",
        "    print(f\"Specificity (Recall for <=50K): {specificity:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    if training_time:\n",
        "        print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "    if pred_time:\n",
        "        print(f\"Prediction Time: {pred_time:.4f} seconds\")\n",
        "\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Sensitivity': sensitivity,\n",
        "        'Specificity': specificity,\n",
        "        'F1 Score': f1,\n",
        "        'Confusion Matrix': cm,\n",
        "        'Training Time': training_time,\n",
        "        'Prediction Time': pred_time\n",
        "    }\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Load data with updated paths\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    train_path = \"/content/drive/MyDrive/Colab Notebooks/train_preprocessed.csv\"\n",
        "    test_path = \"/content/drive/MyDrive/Colab Notebooks/test_preprocessed.csv\"\n",
        "\n",
        "    (X_train_processed, X_test_processed, y_train, y_test,\n",
        "     X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,\n",
        "     preprocessor, input_size) = load_data(train_path, test_path)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 1. Neural Network with PyTorch (GPU-accelerated)\n",
        "    print(\"\\nTraining Neural Network model with PyTorch on GPU...\")\n",
        "    nn_model, nn_preds, nn_training_time = train_nn_model(\n",
        "        X_train_tensor, y_train_tensor, X_test_tensor, input_size, batch_size=128, epochs=20\n",
        "    )\n",
        "    nn_results = evaluate_model(y_test, nn_preds, \"Neural Network (PyTorch)\", training_time=nn_training_time)\n",
        "    results.append(nn_results)\n",
        "\n",
        "    # 2. XGBoost with GPU acceleration\n",
        "    print(\"\\nTraining XGBoost model with GPU acceleration...\")\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective='binary:logistic',\n",
        "            tree_method='gpu_hist',  # GPU acceleration\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train_processed, y_train)\n",
        "        xgb_training_time = time.time() - start_time\n",
        "\n",
        "        # Prediction\n",
        "        start_time = time.time()\n",
        "        xgb_preds = xgb_model.predict(X_test_processed)\n",
        "        xgb_pred_time = time.time() - start_time\n",
        "\n",
        "        xgb_results = evaluate_model(y_test, xgb_preds, \"XGBoost (GPU)\",\n",
        "                                    training_time=xgb_training_time,\n",
        "                                    pred_time=xgb_pred_time)\n",
        "        results.append(xgb_results)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with GPU-accelerated XGBoost: {e}\")\n",
        "        print(\"Falling back to CPU XGBoost\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective='binary:logistic',\n",
        "            tree_method='hist',  # CPU version\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train_processed, y_train)\n",
        "        xgb_training_time = time.time() - start_time\n",
        "\n",
        "        # Prediction\n",
        "        start_time = time.time()\n",
        "        xgb_preds = xgb_model.predict(X_test_processed)\n",
        "        xgb_pred_time = time.time() - start_time\n",
        "\n",
        "        xgb_results = evaluate_model(y_test, xgb_preds, \"XGBoost (CPU)\",\n",
        "                                    training_time=xgb_training_time,\n",
        "                                    pred_time=xgb_pred_time)\n",
        "        results.append(xgb_results)\n",
        "\n",
        "    # 3. Random Forest\n",
        "    print(\"\\nTraining Random Forest model...\")\n",
        "    start_time = time.time()\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        n_jobs=-1,  # Use all CPU cores\n",
        "        random_state=42\n",
        "    )\n",
        "    rf_model.fit(X_train_processed, y_train)\n",
        "    rf_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    rf_preds = rf_model.predict(X_test_processed)\n",
        "    rf_pred_time = time.time() - start_time\n",
        "\n",
        "    rf_results = evaluate_model(y_test, rf_preds, \"Random Forest\",\n",
        "                               training_time=rf_training_time,\n",
        "                               pred_time=rf_pred_time)\n",
        "    results.append(rf_results)\n",
        "\n",
        "    # 4. Logistic Regression\n",
        "    print(\"\\nTraining Logistic Regression model...\")\n",
        "    start_time = time.time()\n",
        "    lr_model = LogisticRegression(\n",
        "        C=1.0,\n",
        "        max_iter=1000,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    lr_model.fit(X_train_processed, y_train)\n",
        "    lr_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    lr_preds = lr_model.predict(X_test_processed)\n",
        "    lr_pred_time = time.time() - start_time\n",
        "\n",
        "    lr_results = evaluate_model(y_test, lr_preds, \"Logistic Regression\",\n",
        "                               training_time=lr_training_time,\n",
        "                               pred_time=lr_pred_time)\n",
        "    results.append(lr_results)\n",
        "\n",
        "    # 5. Lasso Regression\n",
        "    print(\"\\nTraining Lasso Regression model...\")\n",
        "    start_time = time.time()\n",
        "    lasso_model = Lasso(\n",
        "        alpha=0.1,  # Regularization strength\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Lasso expects continuous output, so we'll use a threshold of 0.5 after prediction\n",
        "    lasso_model.fit(X_train_processed, y_train)\n",
        "    lasso_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    lasso_preds_raw = lasso_model.predict(X_test_processed)\n",
        "    lasso_preds = (lasso_preds_raw > 0.5).astype(int)  # Threshold at 0.5\n",
        "    lasso_pred_time = time.time() - start_time\n",
        "\n",
        "    lasso_results = evaluate_model(y_test, lasso_preds, \"Lasso Regression\",\n",
        "                                  training_time=lasso_training_time,\n",
        "                                  pred_time=lasso_pred_time)\n",
        "    results.append(lasso_results)\n",
        "\n",
        "    # 6. Ridge Regression\n",
        "    print(\"\\nTraining Ridge Regression model...\")\n",
        "    start_time = time.time()\n",
        "    ridge_model = Ridge(\n",
        "        alpha=1.0,  # Regularization strength\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Ridge expects continuous output, so we'll use a threshold of 0.5 after prediction\n",
        "    ridge_model.fit(X_train_processed, y_train)\n",
        "    ridge_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    ridge_preds_raw = ridge_model.predict(X_test_processed)\n",
        "    ridge_preds = (ridge_preds_raw > 0.5).astype(int)  # Threshold at 0.5\n",
        "    ridge_pred_time = time.time() - start_time\n",
        "\n",
        "    ridge_results = evaluate_model(y_test, ridge_preds, \"Ridge Regression\",\n",
        "                                  training_time=ridge_training_time,\n",
        "                                  pred_time=ridge_pred_time)\n",
        "    results.append(ridge_results)\n",
        "\n",
        "    # 7. CART Decision Tree\n",
        "    print(\"\\nTraining CART Decision Tree model...\")\n",
        "    start_time = time.time()\n",
        "    dt_model = DecisionTreeClassifier(\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42\n",
        "    )\n",
        "    dt_model.fit(X_train_processed, y_train)\n",
        "    dt_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    dt_preds = dt_model.predict(X_test_processed)\n",
        "    dt_pred_time = time.time() - start_time\n",
        "\n",
        "    dt_results = evaluate_model(y_test, dt_preds, \"CART Decision Tree\",\n",
        "                               training_time=dt_training_time,\n",
        "                               pred_time=dt_pred_time)\n",
        "    results.append(dt_results)\n",
        "\n",
        "    # 8. SVM\n",
        "    print(\"\\nTraining SVM model...\")\n",
        "    start_time = time.time()\n",
        "    svm_model = SVC(\n",
        "        C=1.0,\n",
        "        kernel='rbf',\n",
        "        gamma='scale',\n",
        "        probability=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    svm_model.fit(X_train_processed, y_train)\n",
        "    svm_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    svm_preds = svm_model.predict(X_test_processed)\n",
        "    svm_pred_time = time.time() - start_time\n",
        "\n",
        "    svm_results = evaluate_model(y_test, svm_preds, \"SVM\",\n",
        "                                training_time=svm_training_time,\n",
        "                                pred_time=svm_pred_time)\n",
        "    results.append(svm_results)\n",
        "\n",
        "    # Create comparison DataFrame with F1 scores already included\n",
        "    comparison_df = pd.DataFrame([\n",
        "        {'Model': r['Model'],\n",
        "         'Accuracy': r['Accuracy'],\n",
        "         'Sensitivity': r['Sensitivity'],\n",
        "         'Specificity': r['Specificity'],\n",
        "         'F1 Score': r['F1 Score'],\n",
        "         'Training Time': r.get('Training Time', 'N/A'),\n",
        "         'Prediction Time': r.get('Prediction Time', 'N/A')}\n",
        "        for r in results\n",
        "    ])\n",
        "\n",
        "    print(\"\\n--- Model Comparison ---\")\n",
        "    print(comparison_df)\n",
        "\n",
        "    # Create visualizations for model comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Accuracy, Sensitivity, Specificity comparison\n",
        "    metrics_df = comparison_df[['Model', 'Accuracy', 'Sensitivity', 'Specificity', 'F1 Score']]\n",
        "    metrics_df = pd.melt(metrics_df, id_vars=['Model'], var_name='Metric', value_name='Value')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.barplot(x='Model', y='Value', hue='Metric', data=metrics_df)\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Training Time comparison\n",
        "    plt.subplot(1, 2, 2)\n",
        "    time_df = comparison_df[['Model', 'Training Time']].copy()\n",
        "    time_df = time_df[time_df['Training Time'] != 'N/A']\n",
        "    time_df['Training Time'] = pd.to_numeric(time_df['Training Time'])\n",
        "\n",
        "    sns.barplot(x='Model', y='Training Time', data=time_df)\n",
        "    plt.title('Training Time Comparison (seconds)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig('/content/drive/MyDrive/Colab Notebooks/model_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Find the best model based on different metrics\n",
        "    best_acc_idx = comparison_df['Accuracy'].idxmax()\n",
        "    best_acc_model = comparison_df.loc[best_acc_idx]\n",
        "\n",
        "    best_sens_idx = comparison_df['Sensitivity'].idxmax()\n",
        "    best_sens_model = comparison_df.loc[best_sens_idx]\n",
        "\n",
        "    best_spec_idx = comparison_df['Specificity'].idxmax()\n",
        "    best_spec_model = comparison_df.loc[best_spec_idx]\n",
        "\n",
        "    best_f1_idx = comparison_df['F1 Score'].idxmax()\n",
        "    best_f1_model = comparison_df.loc[best_f1_idx]\n",
        "\n",
        "    # Print the best models\n",
        "    print(f\"\\nBest model based on accuracy: {best_acc_model['Model']} with accuracy {best_acc_model['Accuracy']:.4f}\")\n",
        "    print(f\"Best model based on sensitivity: {best_sens_model['Model']} with sensitivity {best_sens_model['Sensitivity']:.4f}\")\n",
        "    print(f\"Best model based on specificity: {best_spec_model['Model']} with specificity {best_spec_model['Specificity']:.4f}\")\n",
        "    print(f\"Best model based on F1 score: {best_f1_model['Model']} with F1 score {best_f1_model['F1 Score']:.4f}\")\n",
        "\n",
        "    # Determine overall best model (based on accuracy as primary metric)\n",
        "    best_model = best_acc_model\n",
        "    print(f\"\\nOVERALL BEST MODEL: {best_model['Model']}\")\n",
        "    print(f\"  Accuracy: {best_model['Accuracy']:.4f}\")\n",
        "    print(f\"  Sensitivity: {best_model['Sensitivity']:.4f}\")\n",
        "    print(f\"  Specificity: {best_model['Specificity']:.4f}\")\n",
        "    print(f\"  F1 Score: {best_model['F1 Score']:.4f}\")\n",
        "\n",
        "    # Save the comparison results\n",
        "    comparison_df.to_csv('/content/drive/MyDrive/Colab Notebooks/model_comparison_results.csv', index=False)\n",
        "\n",
        "    # Write a summary of results\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/model_summary.txt', 'w') as f:\n",
        "        f.write(\"Income Prediction Model Comparison\\n\")\n",
        "        f.write(\"=================================\\n\\n\")\n",
        "        f.write(f\"Best model based on accuracy: {best_acc_model['Model']}\\n\")\n",
        "        f.write(f\"  Accuracy: {best_acc_model['Accuracy']:.4f}\\n\")\n",
        "        f.write(f\"  Sensitivity: {best_acc_model['Sensitivity']:.4f}\\n\")\n",
        "        f.write(f\"  Specificity: {best_acc_model['Specificity']:.4f}\\n\")\n",
        "        f.write(f\"  F1 Score: {best_acc_model['F1 Score']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Best model based on F1 score: {best_f1_model['Model']}\\n\")\n",
        "        f.write(f\"  F1 Score: {best_f1_model['F1 Score']:.4f}\\n\")\n",
        "        f.write(f\"  Accuracy: {best_f1_model['Accuracy']:.4f}\\n\")\n",
        "        f.write(f\"  Sensitivity: {best_f1_model['Sensitivity']:.4f}\\n\")\n",
        "        f.write(f\"  Specificity: {best_f1_model['Specificity']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"All Models Performance:\\n\")\n",
        "        f.write(comparison_df.to_string())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4qMUZJtrGgX",
        "outputId": "3bed360d-b344-422f-d1a5-47ffbc63c0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading and preprocessing data...\n",
            "Numeric features: ['age', 'education-num', 'hours-per-week']\n",
            "Categorical features: ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "X_train shape after preprocessing: (24147, 85)\n",
            "X_test shape after preprocessing: (6015, 85)\n",
            "\n",
            "Training Neural Network model with PyTorch on GPU...\n",
            "Epoch [5/20], Loss: 0.3515\n",
            "Epoch [10/20], Loss: 0.3431\n",
            "Epoch [15/20], Loss: 0.3406\n",
            "Epoch [20/20], Loss: 0.3374\n",
            "Training completed in 21.72 seconds\n",
            "\n",
            "--- Neural Network (PyTorch) Results ---\n",
            "Confusion Matrix:\n",
            "[[4072  456]\n",
            " [ 571  916]]\n",
            "Accuracy: 0.8293\n",
            "Sensitivity (Recall for >50K): 0.6160\n",
            "Specificity (Recall for <=50K): 0.8993\n",
            "F1 Score: 0.6408\n",
            "Training Time: 21.7173 seconds\n",
            "\n",
            "Training XGBoost model with GPU acceleration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:32:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:32:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost (GPU) Results ---\n",
            "Confusion Matrix:\n",
            "[[4147  381]\n",
            " [ 612  875]]\n",
            "Accuracy: 0.8349\n",
            "Sensitivity (Recall for >50K): 0.5884\n",
            "Specificity (Recall for <=50K): 0.9159\n",
            "F1 Score: 0.6380\n",
            "Training Time: 0.5591 seconds\n",
            "Prediction Time: 0.0163 seconds\n",
            "\n",
            "Training Random Forest model...\n",
            "\n",
            "--- Random Forest Results ---\n",
            "Confusion Matrix:\n",
            "[[4260  268]\n",
            " [ 774  713]]\n",
            "Accuracy: 0.8268\n",
            "Sensitivity (Recall for >50K): 0.4795\n",
            "Specificity (Recall for <=50K): 0.9408\n",
            "F1 Score: 0.5778\n",
            "Training Time: 1.1428 seconds\n",
            "Prediction Time: 0.0442 seconds\n",
            "\n",
            "Training Logistic Regression model...\n",
            "\n",
            "--- Logistic Regression Results ---\n",
            "Confusion Matrix:\n",
            "[[4136  392]\n",
            " [ 660  827]]\n",
            "Accuracy: 0.8251\n",
            "Sensitivity (Recall for >50K): 0.5562\n",
            "Specificity (Recall for <=50K): 0.9134\n",
            "F1 Score: 0.6112\n",
            "Training Time: 1.5079 seconds\n",
            "Prediction Time: 0.0015 seconds\n",
            "\n",
            "Training Lasso Regression model...\n",
            "\n",
            "--- Lasso Regression Results ---\n",
            "Confusion Matrix:\n",
            "[[4528    0]\n",
            " [1487    0]]\n",
            "Accuracy: 0.7528\n",
            "Sensitivity (Recall for >50K): 0.0000\n",
            "Specificity (Recall for <=50K): 1.0000\n",
            "F1 Score: 0.0000\n",
            "Training Time: 0.1270 seconds\n",
            "Prediction Time: 0.0013 seconds\n",
            "\n",
            "Training Ridge Regression model...\n",
            "\n",
            "--- Ridge Regression Results ---\n",
            "Confusion Matrix:\n",
            "[[4185  343]\n",
            " [ 707  780]]\n",
            "Accuracy: 0.8254\n",
            "Sensitivity (Recall for >50K): 0.5245\n",
            "Specificity (Recall for <=50K): 0.9242\n",
            "F1 Score: 0.5977\n",
            "Training Time: 0.0327 seconds\n",
            "Prediction Time: 0.0010 seconds\n",
            "\n",
            "Training CART Decision Tree model...\n",
            "\n",
            "--- CART Decision Tree Results ---\n",
            "Confusion Matrix:\n",
            "[[4074  454]\n",
            " [ 603  884]]\n",
            "Accuracy: 0.8243\n",
            "Sensitivity (Recall for >50K): 0.5945\n",
            "Specificity (Recall for <=50K): 0.8997\n",
            "F1 Score: 0.6258\n",
            "Training Time: 0.1695 seconds\n",
            "Prediction Time: 0.0019 seconds\n",
            "\n",
            "Training SVM model...\n",
            "\n",
            "--- SVM Results ---\n",
            "Confusion Matrix:\n",
            "[[4188  340]\n",
            " [ 669  818]]\n",
            "Accuracy: 0.8323\n",
            "Sensitivity (Recall for >50K): 0.5501\n",
            "Specificity (Recall for <=50K): 0.9249\n",
            "F1 Score: 0.6185\n",
            "Training Time: 123.4748 seconds\n",
            "Prediction Time: 5.6052 seconds\n",
            "\n",
            "--- Model Comparison ---\n",
            "                      Model  Accuracy  Sensitivity  Specificity  F1 Score  \\\n",
            "0  Neural Network (PyTorch)  0.829260     0.616005     0.899293  0.640783   \n",
            "1             XGBoost (GPU)  0.834913     0.588433     0.915857  0.637988   \n",
            "2             Random Forest  0.826766     0.479489     0.940813  0.577796   \n",
            "3       Logistic Regression  0.825104     0.556153     0.913428  0.611234   \n",
            "4          Lasso Regression  0.752785     0.000000     1.000000  0.000000   \n",
            "5          Ridge Regression  0.825436     0.524546     0.924249  0.597701   \n",
            "6        CART Decision Tree  0.824273     0.594486     0.899735  0.625841   \n",
            "7                       SVM  0.832253     0.550101     0.924912  0.618526   \n",
            "\n",
            "   Training Time  Prediction Time  \n",
            "0      21.717332              NaN  \n",
            "1       0.559052         0.016272  \n",
            "2       1.142822         0.044209  \n",
            "3       1.507900         0.001503  \n",
            "4       0.126953         0.001295  \n",
            "5       0.032686         0.001017  \n",
            "6       0.169506         0.001915  \n",
            "7     123.474806         5.605166  \n",
            "\n",
            "Best model based on accuracy: XGBoost (GPU) with accuracy 0.8349\n",
            "Best model based on sensitivity: Neural Network (PyTorch) with sensitivity 0.6160\n",
            "Best model based on specificity: Lasso Regression with specificity 1.0000\n",
            "Best model based on F1 score: Neural Network (PyTorch) with F1 score 0.6408\n",
            "\n",
            "OVERALL BEST MODEL: XGBoost (GPU)\n",
            "  Accuracy: 0.8349\n",
            "  Sensitivity: 0.5884\n",
            "  Specificity: 0.9159\n",
            "  F1 Score: 0.6380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, recall_score, classification_report,\n",
        "                            f1_score, precision_score, roc_auc_score, average_precision_score,\n",
        "                            matthews_corrcoef, balanced_accuracy_score, precision_recall_curve)\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_data(train_path, test_path):\n",
        "    # Load the preprocessed data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop('income', axis=1)\n",
        "    y_train = (train_data['income'] == '>50K').astype(int)  # Convert to binary (0 for <=50K, 1 for >50K)\n",
        "\n",
        "    X_test = test_data.drop('income', axis=1)\n",
        "    y_test = (test_data['income'] == '>50K').astype(int)\n",
        "\n",
        "    # Identify numeric and categorical columns\n",
        "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    print(f\"Numeric features: {numeric_features}\")\n",
        "    print(f\"Categorical features: {categorical_features}\")\n",
        "\n",
        "    # Create preprocessing pipelines\n",
        "    # For numeric features: standard scaling\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # For categorical features: one-hot encoding\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing steps\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Apply preprocessing\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "    # Get feature names after one-hot encoding\n",
        "    categorical_feature_names = []\n",
        "    if categorical_features:\n",
        "        categorical_feature_names = list(\n",
        "            preprocessor.named_transformers_['cat']['onehot']\n",
        "            .get_feature_names_out(categorical_features)\n",
        "        )\n",
        "\n",
        "    all_feature_names = numeric_features + categorical_feature_names\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(X_train_processed).to(device)\n",
        "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
        "    X_test_tensor = torch.FloatTensor(X_test_processed).to(device)\n",
        "    y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1).to(device)\n",
        "\n",
        "    print(f\"X_train shape after preprocessing: {X_train_processed.shape}\")\n",
        "    print(f\"X_test shape after preprocessing: {X_test_processed.shape}\")\n",
        "\n",
        "    return (X_train_processed, X_test_processed, y_train.values, y_test.values,\n",
        "            X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,\n",
        "            preprocessor, X_train_processed.shape[1])\n",
        "\n",
        "# Neural Network Model using PyTorch\n",
        "class IncomeNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(IncomeNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
        "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
        "        x = self.dropout(self.relu(self.bn3(self.fc3(x))))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# Function to train the PyTorch neural network\n",
        "def train_nn_model(X_train_tensor, y_train_tensor, X_test_tensor, input_size, batch_size=64, epochs=20):\n",
        "    # Create DataLoader for batching\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = IncomeNN(input_size).to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print statistics\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f'Training completed in {training_time:.2f} seconds')\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Make predictions\n",
        "        y_pred_proba = model(X_test_tensor)\n",
        "        y_pred = (y_pred_proba > 0.5).cpu().numpy().astype(int).flatten()\n",
        "        y_pred_proba = y_pred_proba.cpu().numpy().flatten()\n",
        "\n",
        "    return model, y_pred, y_pred_proba, training_time\n",
        "\n",
        "# Enhanced function to evaluate models\n",
        "def evaluate_model(y_test, y_pred, y_pred_proba=None, model_name=\"Model\", training_time=None, pred_time=None):\n",
        "    # Calculate basic metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Precision (Positive Predictive Value)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    # Sensitivity/Recall (True Positive Rate)\n",
        "    sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "    # Specificity (True Negative Rate)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # F1 score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Matthews Correlation Coefficient (MCC)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    # Calculate AUC-ROC and Average Precision (AP) if probability scores are available\n",
        "    auc_roc = None\n",
        "    avg_precision = None\n",
        "\n",
        "    if y_pred_proba is not None:\n",
        "        try:\n",
        "            auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
        "            avg_precision = average_precision_score(y_test, y_pred_proba)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate AUC/AP: {e}\")\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\n--- {model_name} Results ---\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Sensitivity/Recall: {sensitivity:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "\n",
        "    if auc_roc is not None:\n",
        "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "    if avg_precision is not None:\n",
        "        print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "\n",
        "    if training_time:\n",
        "        print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "    if pred_time:\n",
        "        print(f\"Prediction Time: {pred_time:.4f} seconds\")\n",
        "\n",
        "    # Return all metrics as a dictionary\n",
        "    results = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Balanced Accuracy': balanced_acc,\n",
        "        'Precision': precision,\n",
        "        'Sensitivity': sensitivity,\n",
        "        'Specificity': specificity,\n",
        "        'F1 Score': f1,\n",
        "        'MCC': mcc,\n",
        "        'Confusion Matrix': cm,\n",
        "        'Training Time': training_time,\n",
        "        'Prediction Time': pred_time\n",
        "    }\n",
        "\n",
        "    if auc_roc is not None:\n",
        "        results['AUC-ROC'] = auc_roc\n",
        "    if avg_precision is not None:\n",
        "        results['AP'] = avg_precision\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to visualize model comparison\n",
        "def visualize_model_comparison(results, save_path=None):\n",
        "    # Create comparison DataFrame\n",
        "    comparison_df = pd.DataFrame([\n",
        "        {'Model': r['Model'],\n",
        "         'Accuracy': r['Accuracy'],\n",
        "         'Balanced Accuracy': r.get('Balanced Accuracy', 'N/A'),\n",
        "         'Precision': r['Precision'],\n",
        "         'Sensitivity': r['Sensitivity'],\n",
        "         'Specificity': r['Specificity'],\n",
        "         'F1 Score': r['F1 Score'],\n",
        "         'MCC': r.get('MCC', 'N/A'),\n",
        "         'AUC-ROC': r.get('AUC-ROC', 'N/A'),\n",
        "         'AP': r.get('AP', 'N/A'),\n",
        "         'Training Time': r.get('Training Time', 'N/A'),\n",
        "         'Prediction Time': r.get('Prediction Time', 'N/A')}\n",
        "        for r in results\n",
        "    ])\n",
        "\n",
        "    print(\"\\n--- Model Comparison ---\")\n",
        "    print(comparison_df)\n",
        "\n",
        "    # Create visualizations for model comparison\n",
        "    plt.figure(figsize=(20, 12))\n",
        "\n",
        "    # Performance metrics comparison\n",
        "    metrics_to_plot = ['Accuracy', 'Balanced Accuracy', 'Precision', 'Sensitivity',\n",
        "                      'Specificity', 'F1 Score', 'MCC']\n",
        "\n",
        "    metrics_df = comparison_df[['Model'] + metrics_to_plot].copy()\n",
        "    for col in metrics_to_plot:\n",
        "        metrics_df[col] = pd.to_numeric(metrics_df[col], errors='coerce')\n",
        "\n",
        "    metrics_df = pd.melt(metrics_df, id_vars=['Model'], var_name='Metric', value_name='Value')\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.barplot(x='Model', y='Value', hue='Metric', data=metrics_df)\n",
        "    plt.title('Model Performance Metrics Comparison')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # Training Time comparison\n",
        "    plt.subplot(2, 2, 2)\n",
        "    time_df = comparison_df[['Model', 'Training Time']].copy()\n",
        "    time_df = time_df[time_df['Training Time'] != 'N/A']\n",
        "    time_df['Training Time'] = pd.to_numeric(time_df['Training Time'])\n",
        "\n",
        "    sns.barplot(x='Model', y='Training Time', data=time_df)\n",
        "    plt.title('Training Time Comparison (seconds)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Prediction Time comparison\n",
        "    plt.subplot(2, 2, 3)\n",
        "    pred_time_df = comparison_df[['Model', 'Prediction Time']].copy()\n",
        "    pred_time_df = pred_time_df[pred_time_df['Prediction Time'] != 'N/A']\n",
        "    pred_time_df['Prediction Time'] = pd.to_numeric(pred_time_df['Prediction Time'])\n",
        "\n",
        "    sns.barplot(x='Model', y='Prediction Time', data=pred_time_df)\n",
        "    plt.title('Prediction Time Comparison (seconds)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Advanced metrics comparison (AUC, AP)\n",
        "    plt.subplot(2, 2, 4)\n",
        "    adv_metrics = ['AUC-ROC', 'AP']\n",
        "    adv_df = comparison_df[['Model'] + adv_metrics].copy()\n",
        "\n",
        "    # Convert to numeric, handling 'N/A' values\n",
        "    for col in adv_metrics:\n",
        "        adv_df[col] = pd.to_numeric(adv_df[col], errors='coerce')\n",
        "\n",
        "    # Drop rows where all advanced metrics are NaN\n",
        "    adv_df = adv_df.dropna(subset=adv_metrics, how='all')\n",
        "\n",
        "    if not adv_df.empty:\n",
        "        adv_melted = pd.melt(adv_df, id_vars=['Model'], var_name='Metric', value_name='Value')\n",
        "        sns.barplot(x='Model', y='Value', hue='Metric', data=adv_melted)\n",
        "        plt.title('Advanced Metrics Comparison (AUC-ROC & Average Precision)')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylim(0, 1)\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No AUC-ROC or AP data available',\n",
        "                ha='center', va='center', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Visualization saved to {save_path}\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Load data with updated paths\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    train_path = \"/content/drive/MyDrive/Colab Notebooks/train_preprocessed.csv\"\n",
        "    test_path = \"/content/drive/MyDrive/Colab Notebooks/test_preprocessed.csv\"\n",
        "\n",
        "    (X_train_processed, X_test_processed, y_train, y_test,\n",
        "     X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,\n",
        "     preprocessor, input_size) = load_data(train_path, test_path)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 1. Neural Network with PyTorch (GPU-accelerated)\n",
        "    print(\"\\nTraining Neural Network model with PyTorch on GPU...\")\n",
        "    nn_model, nn_preds, nn_pred_proba, nn_training_time = train_nn_model(\n",
        "        X_train_tensor, y_train_tensor, X_test_tensor, input_size, batch_size=128, epochs=20\n",
        "    )\n",
        "    nn_results = evaluate_model(y_test, nn_preds, nn_pred_proba, \"Neural Network (PyTorch)\",\n",
        "                              training_time=nn_training_time)\n",
        "    results.append(nn_results)\n",
        "\n",
        "    # 2. XGBoost with GPU acceleration\n",
        "    print(\"\\nTraining XGBoost model with GPU acceleration...\")\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective='binary:logistic',\n",
        "            tree_method='gpu_hist',  # GPU acceleration\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train_processed, y_train)\n",
        "        xgb_training_time = time.time() - start_time\n",
        "\n",
        "        # Prediction\n",
        "        start_time = time.time()\n",
        "        xgb_preds = xgb_model.predict(X_test_processed)\n",
        "        xgb_pred_proba = xgb_model.predict_proba(X_test_processed)[:, 1]  # Get positive class probabilities\n",
        "        xgb_pred_time = time.time() - start_time\n",
        "\n",
        "        xgb_results = evaluate_model(y_test, xgb_preds, xgb_pred_proba, \"XGBoost (GPU)\",\n",
        "                                   training_time=xgb_training_time,\n",
        "                                   pred_time=xgb_pred_time)\n",
        "        results.append(xgb_results)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with GPU-accelerated XGBoost: {e}\")\n",
        "        print(\"Falling back to CPU XGBoost\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective='binary:logistic',\n",
        "            tree_method='hist',  # CPU version\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train_processed, y_train)\n",
        "        xgb_training_time = time.time() - start_time\n",
        "\n",
        "        # Prediction\n",
        "        start_time = time.time()\n",
        "        xgb_preds = xgb_model.predict(X_test_processed)\n",
        "        xgb_pred_proba = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
        "        xgb_pred_time = time.time() - start_time\n",
        "\n",
        "        xgb_results = evaluate_model(y_test, xgb_preds, xgb_pred_proba, \"XGBoost (CPU)\",\n",
        "                                   training_time=xgb_training_time,\n",
        "                                   pred_time=xgb_pred_time)\n",
        "        results.append(xgb_results)\n",
        "\n",
        "    # 3. Random Forest\n",
        "    print(\"\\nTraining Random Forest model...\")\n",
        "    start_time = time.time()\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        n_jobs=-1,  # Use all CPU cores\n",
        "        random_state=42\n",
        "    )\n",
        "    rf_model.fit(X_train_processed, y_train)\n",
        "    rf_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    rf_preds = rf_model.predict(X_test_processed)\n",
        "    rf_pred_proba = rf_model.predict_proba(X_test_processed)[:, 1]\n",
        "    rf_pred_time = time.time() - start_time\n",
        "\n",
        "    rf_results = evaluate_model(y_test, rf_preds, rf_pred_proba, \"Random Forest\",\n",
        "                              training_time=rf_training_time,\n",
        "                              pred_time=rf_pred_time)\n",
        "    results.append(rf_results)\n",
        "\n",
        "    # 4. Logistic Regression\n",
        "    print(\"\\nTraining Logistic Regression model...\")\n",
        "    start_time = time.time()\n",
        "    lr_model = LogisticRegression(\n",
        "        C=1.0,\n",
        "        max_iter=1000,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    lr_model.fit(X_train_processed, y_train)\n",
        "    lr_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    lr_preds = lr_model.predict(X_test_processed)\n",
        "    lr_pred_proba = lr_model.predict_proba(X_test_processed)[:, 1]\n",
        "    lr_pred_time = time.time() - start_time\n",
        "\n",
        "    lr_results = evaluate_model(y_test, lr_preds, lr_pred_proba, \"Logistic Regression\",\n",
        "                              training_time=lr_training_time,\n",
        "                              pred_time=lr_pred_time)\n",
        "    results.append(lr_results)\n",
        "\n",
        "    # 5. Lasso Regression\n",
        "    print(\"\\nTraining Lasso Regression model...\")\n",
        "    start_time = time.time()\n",
        "    lasso_model = Lasso(\n",
        "        alpha=0.1,  # Regularization strength\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Lasso expects continuous output, so we'll use a threshold of 0.5 after prediction\n",
        "    lasso_model.fit(X_train_processed, y_train)\n",
        "    lasso_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    lasso_preds_raw = lasso_model.predict(X_test_processed)\n",
        "    lasso_preds = (lasso_preds_raw > 0.5).astype(int)  # Threshold at 0.5\n",
        "    lasso_pred_time = time.time() - start_time\n",
        "\n",
        "    # Clip predictions to be between 0 and 1 for metrics calculation\n",
        "    lasso_pred_proba = np.clip(lasso_preds_raw, 0, 1)\n",
        "\n",
        "    lasso_results = evaluate_model(y_test, lasso_preds, lasso_pred_proba, \"Lasso Regression\",\n",
        "                                 training_time=lasso_training_time,\n",
        "                                 pred_time=lasso_pred_time)\n",
        "    results.append(lasso_results)\n",
        "\n",
        "    # 6. Ridge Regression\n",
        "    print(\"\\nTraining Ridge Regression model...\")\n",
        "    start_time = time.time()\n",
        "    ridge_model = Ridge(\n",
        "        alpha=1.0,  # Regularization strength\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Ridge expects continuous output, so we'll use a threshold of 0.5 after prediction\n",
        "    ridge_model.fit(X_train_processed, y_train)\n",
        "    ridge_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    ridge_preds_raw = ridge_model.predict(X_test_processed)\n",
        "    ridge_preds = (ridge_preds_raw > 0.5).astype(int)  # Threshold at 0.5\n",
        "    ridge_pred_time = time.time() - start_time\n",
        "\n",
        "    # Clip predictions to be between 0 and 1 for metrics calculation\n",
        "    ridge_pred_proba = np.clip(ridge_preds_raw, 0, 1)\n",
        "\n",
        "    ridge_results = evaluate_model(y_test, ridge_preds, ridge_pred_proba, \"Ridge Regression\",\n",
        "                                 training_time=ridge_training_time,\n",
        "                                 pred_time=ridge_pred_time)\n",
        "    results.append(ridge_results)\n",
        "\n",
        "    # 7. CART Decision Tree\n",
        "    print(\"\\nTraining CART Decision Tree model...\")\n",
        "    start_time = time.time()\n",
        "    dt_model = DecisionTreeClassifier(\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42\n",
        "    )\n",
        "    dt_model.fit(X_train_processed, y_train)\n",
        "    dt_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    dt_preds = dt_model.predict(X_test_processed)\n",
        "    dt_pred_proba = dt_model.predict_proba(X_test_processed)[:, 1]\n",
        "    dt_pred_time = time.time() - start_time\n",
        "\n",
        "    dt_results = evaluate_model(y_test, dt_preds, dt_pred_proba, \"CART Decision Tree\",\n",
        "                              training_time=dt_training_time,\n",
        "                              pred_time=dt_pred_time)\n",
        "    results.append(dt_results)\n",
        "\n",
        "    # 8. SVM\n",
        "    print(\"\\nTraining SVM model...\")\n",
        "    start_time = time.time()\n",
        "    svm_model = SVC(\n",
        "        C=1.0,\n",
        "        kernel='rbf',\n",
        "        gamma='scale',\n",
        "        probability=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    svm_model.fit(X_train_processed, y_train)\n",
        "    svm_training_time = time.time() - start_time\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    svm_preds = svm_model.predict(X_test_processed)\n",
        "    svm_pred_proba = svm_model.predict_proba(X_test_processed)[:, 1]\n",
        "    svm_pred_time = time.time() - start_time\n",
        "\n",
        "    svm_results = evaluate_model(y_test, svm_preds, svm_pred_proba, \"SVM\",\n",
        "                               training_time=svm_training_time,\n",
        "                               pred_time=svm_pred_time)\n",
        "    results.append(svm_results)\n",
        "\n",
        "    # Create comparison visualization and get DataFrame\n",
        "    comparison_df = visualize_model_comparison(results,\n",
        "                                             save_path='/content/drive/MyDrive/Colab Notebooks/enhanced_model_comparison.png')\n",
        "\n",
        "    # Find the best models based on different metrics\n",
        "    metrics_to_check = ['Accuracy', 'Balanced Accuracy', 'Precision', 'Sensitivity',\n",
        "                       'Specificity', 'F1 Score', 'MCC']\n",
        "\n",
        "    best_models = {}\n",
        "    for metric in metrics_to_check:\n",
        "        if metric in comparison_df.columns:\n",
        "            # Convert to numeric first in case there are 'N/A' values\n",
        "            comparison_df[metric] = pd.to_numeric(comparison_df[metric], errors='coerce')\n",
        "            if not comparison_df[metric].isna().all():\n",
        "                best_idx = comparison_df[metric].idxmax()\n",
        "                best_models[metric] = {\n",
        "                    'Model': comparison_df.loc[best_idx, 'Model'],\n",
        "                    'Value': comparison_df.loc[best_idx, metric]\n",
        "                }\n",
        "\n",
        "    # Print the best models\n",
        "    print(\"\\n--- Best Models by Metric ---\")\n",
        "    for metric, info in best_models.items():\n",
        "        print(f\"Best model based on {metric}: {info['Model']} with {metric} {info['Value']:.4f}\")\n",
        "\n",
        "    # Determine overall best model (using F1 score as primary metric if available)\n",
        "    overall_best = best_models.get('F1 Score', best_models.get('Accuracy'))\n",
        "    if overall_best:\n",
        "        best_model_name = overall_best['Model']\n",
        "        best_model_idx = comparison_df[comparison_df['Model'] == best_model_name].index[0]\n",
        "        best_model = comparison_df.loc[best_model_idx]\n",
        "\n",
        "        print(f\"\\nOVERALL BEST MODEL: {best_model['Model']}\")\n",
        "        for metric in metrics_to_check:\n",
        "            if metric in best_model and best_model[metric] != 'N/A':\n",
        "                print(f\"  {metric}: {best_model[metric]:.4f}\")\n",
        "\n",
        "    # Save the comparison results\n",
        "    comparison_df.to_csv('/content/drive/MyDrive/Colab Notebooks/enhanced_model_comparison_results.csv', index=False)\n",
        "\n",
        "    # Create precision-recall curves for models with probability outputs\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for result in results:\n",
        "        model_name = result['Model']\n",
        "        # Check if we have probability predictions\n",
        "        if 'AP' in result:\n",
        "            try:\n",
        "                # Get the original y_test and y_pred_proba from the result\n",
        "                model_idx = [i for i, r in enumerate(results) if r['Model'] == model_name][0]\n",
        "\n",
        "                if model_name == \"Neural Network (PyTorch)\":\n",
        "                    y_pred_proba = nn_pred_proba\n",
        "                elif \"XGBoost\" in model_name:\n",
        "                    y_pred_proba = xgb_pred_proba\n",
        "                elif model_name == \"Random Forest\":\n",
        "                    y_pred_proba = rf_pred_proba\n",
        "                elif model_name == \"Logistic Regression\":\n",
        "                    y_pred_proba = lr_pred_proba\n",
        "                elif model_name == \"Lasso Regression\":\n",
        "                    y_pred_proba = lasso_pred_proba\n",
        "                elif model_name == \"Ridge Regression\":\n",
        "                    y_pred_proba = ridge_pred_proba\n",
        "                elif model_name == \"CART Decision Tree\":\n",
        "                    y_pred_proba = dt_pred_proba\n",
        "                elif model_name == \"SVM\":\n",
        "                    y_pred_proba = svm_pred_proba\n",
        "\n",
        "                precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "                plt.plot(recall, precision, label=f'{model_name} (AP={result[\"AP\"]:.4f})')\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating PR curve for {model_name}: {e}\")\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curves')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "    plt.savefig('/content/drive/MyDrive/Colab Notebooks/precision_recall_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Write a comprehensive summary of results\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/enhanced_model_summary.txt', 'w') as f:\n",
        "        f.write(\"Income Prediction Model Comparison - Enhanced Evaluation\\n\")\n",
        "        f.write(\"====================================================\\n\\n\")\n",
        "\n",
        "        # Write best models by each metric\n",
        "        f.write(\"Best Models by Evaluation Metric:\\n\")\n",
        "        f.write(\"--------------------------------\\n\")\n",
        "        for metric, info in best_models.items():\n",
        "            f.write(f\"Best model based on {metric}: {info['Model']} with {metric} {info['Value']:.4f}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # Write overall best model details\n",
        "        if overall_best:\n",
        "            f.write(\"OVERALL BEST MODEL DETAILS\\n\")\n",
        "            f.write(\"-------------------------\\n\")\n",
        "            f.write(f\"Model: {best_model['Model']}\\n\")\n",
        "            for metric in metrics_to_check:\n",
        "                if metric in best_model and best_model[metric] != 'N/A':\n",
        "                    f.write(f\"{metric}: {best_model[metric]:.4f}\\n\")\n",
        "\n",
        "            # Add training and prediction time if available\n",
        "            if 'Training Time' in best_model and best_model['Training Time'] != 'N/A':\n",
        "                f.write(f\"Training Time: {best_model['Training Time']:.4f} seconds\\n\")\n",
        "            if 'Prediction Time' in best_model and best_model['Prediction Time'] != 'N/A':\n",
        "                f.write(f\"Prediction Time: {best_model['Prediction Time']:.4f} seconds\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        # Table of all models and their performance\n",
        "        f.write(\"Complete Model Performance Comparison:\\n\")\n",
        "        f.write(\"-----------------------------------\\n\")\n",
        "        f.write(comparison_df.to_string(index=False))\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        # Add interpretation and recommendations\n",
        "        f.write(\"Evaluation Metrics Explanation:\\n\")\n",
        "        f.write(\"----------------------------\\n\")\n",
        "        f.write(\"- Accuracy: Overall correctness (correct predictions / total predictions)\\n\")\n",
        "        f.write(\"- Balanced Accuracy: Average of sensitivity and specificity (accounts for class imbalance)\\n\")\n",
        "        f.write(\"- Precision: Positive predictive value (true positives / predicted positives)\\n\")\n",
        "        f.write(\"- Sensitivity/Recall: True positive rate (true positives / actual positives)\\n\")\n",
        "        f.write(\"- Specificity: True negative rate (true negatives / actual negatives)\\n\")\n",
        "        f.write(\"- F1 Score: Harmonic mean of precision and recall (balances both metrics)\\n\")\n",
        "        f.write(\"- MCC: Matthews Correlation Coefficient (balanced measure that works well with imbalanced data)\\n\")\n",
        "        f.write(\"- AUC-ROC: Area Under the ROC Curve (discrimination ability at various thresholds)\\n\")\n",
        "        f.write(\"- AP: Average Precision (area under precision-recall curve)\\n\")\n",
        "\n",
        "        f.write(\"\\n\\nConclusion and Recommendations:\\n\")\n",
        "        f.write(\"-----------------------------\\n\")\n",
        "        if overall_best:\n",
        "            f.write(f\"The {best_model['Model']} model demonstrated the best overall performance for this income prediction task.\\n\")\n",
        "\n",
        "            # Add specific recommendations based on the results\n",
        "            f.write(\"\\nKey observations:\\n\")\n",
        "            f.write(\"1. Performance-speed tradeoff: Neural networks and tree-based models generally performed better but took longer to train.\\n\")\n",
        "            f.write(\"2. Linear models like logistic regression offered reasonable performance with faster training times.\\n\")\n",
        "            f.write(\"3. Consider the most important metric for your specific application when selecting a model.\\n\")\n",
        "            f.write(\"4. For deployment in a production environment, consider both model accuracy and inference speed.\\n\")\n",
        "\n",
        "def plot_confusion_matrices(results, save_path='/content/drive/MyDrive/Colab Notebooks/confusion_matrices.png'):\n",
        "    \"\"\"\n",
        "    Create a figure with confusion matrices for all models\n",
        "    \"\"\"\n",
        "    # Determine grid size based on number of models\n",
        "    n_models = len(results)\n",
        "    n_cols = min(4, n_models)\n",
        "    n_rows = (n_models + n_cols - 1) // n_cols\n",
        "\n",
        "    plt.figure(figsize=(n_cols * 5, n_rows * 4))\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "\n",
        "        cm = result['Confusion Matrix']\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "        # Calculate and display percentages\n",
        "        cm_sum = np.sum(cm)\n",
        "        cm_percentages = cm / cm_sum * 100\n",
        "\n",
        "        # Add text annotations with percentages\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                text_color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
        "                plt.text(j + 0.5, i + 0.7, f'({cm_percentages[i, j]:.1f}%)',\n",
        "                        ha='center', va='center', color=text_color, fontsize=9)\n",
        "\n",
        "        plt.title(result['Model'])\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.tight_layout()\n",
        "\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrices saved to {save_path}\")\n",
        "\n",
        "def plot_feature_importance(X_train_processed, preprocessor, models, save_path='/content/drive/MyDrive/Colab Notebooks/feature_importance.png'):\n",
        "    \"\"\"\n",
        "    Plot feature importance for models that support it\n",
        "    \"\"\"\n",
        "    # Get feature names\n",
        "    numeric_features = preprocessor.transformers_[0][2]\n",
        "    categorical_features = preprocessor.transformers_[1][2]\n",
        "\n",
        "    # Get one-hot encoded feature names\n",
        "    categorical_feature_names = []\n",
        "    if len(categorical_features) > 0:\n",
        "        try:\n",
        "            categorical_feature_names = list(\n",
        "                preprocessor.named_transformers_['cat']['onehot']\n",
        "                .get_feature_names_out(categorical_features)\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    all_feature_names = list(numeric_features) + list(categorical_feature_names)\n",
        "\n",
        "    # Models that support feature importance\n",
        "    importance_models = {\n",
        "        'xgb_model': 'XGBoost',\n",
        "        'rf_model': 'Random Forest',\n",
        "        'dt_model': 'Decision Tree'\n",
        "    }\n",
        "\n",
        "    available_models = {name: model for name, model in models.items() if name in importance_models}\n",
        "\n",
        "    if len(available_models) == 0:\n",
        "        print(\"No models with feature importance available\")\n",
        "        return\n",
        "\n",
        "    n_models = len(available_models)\n",
        "    plt.figure(figsize=(12, n_models * 6))\n",
        "\n",
        "    for i, (model_var, model) in enumerate(available_models.items()):\n",
        "        plt.subplot(n_models, 1, i + 1)\n",
        "\n",
        "        # Extract feature importance\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "        elif hasattr(model, 'coef_'):\n",
        "            importances = np.abs(model.coef_[0])\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Ensure we have the right number of feature names\n",
        "        if len(importances) != len(all_feature_names):\n",
        "            # If there's a mismatch, create generic feature names\n",
        "            all_feature_names = [f\"Feature {i}\" for i in range(len(importances))]\n",
        "\n",
        "        # Sort features by importance\n",
        "        indices = np.argsort(importances)[-20:]  # Top 20 features\n",
        "\n",
        "        plt.barh(range(len(indices)), importances[indices])\n",
        "        plt.yticks(range(len(indices)), [all_feature_names[i] for i in indices])\n",
        "        plt.title(f'Top Features - {importance_models[model_var]}')\n",
        "        plt.xlabel('Importance')\n",
        "        plt.tight_layout()\n",
        "\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Feature importance plot saved to {save_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjxxVTq8vG3b",
        "outputId": "73953345-5422-46d6-e93f-4a00c3e785e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading and preprocessing data...\n",
            "Numeric features: ['age', 'education-num', 'hours-per-week']\n",
            "Categorical features: ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "X_train shape after preprocessing: (24147, 85)\n",
            "X_test shape after preprocessing: (6015, 85)\n",
            "\n",
            "Training Neural Network model with PyTorch on GPU...\n",
            "Epoch [5/20], Loss: 0.3515\n",
            "Epoch [10/20], Loss: 0.3431\n",
            "Epoch [15/20], Loss: 0.3406\n",
            "Epoch [20/20], Loss: 0.3374\n",
            "Training completed in 16.44 seconds\n",
            "\n",
            "--- Neural Network (PyTorch) Results ---\n",
            "Confusion Matrix:\n",
            "[[4072  456]\n",
            " [ 571  916]]\n",
            "Accuracy: 0.8293\n",
            "Balanced Accuracy: 0.7576\n",
            "Precision: 0.6676\n",
            "Sensitivity/Recall: 0.6160\n",
            "Specificity: 0.8993\n",
            "F1 Score: 0.6408\n",
            "Matthews Correlation Coefficient: 0.5298\n",
            "AUC-ROC: 0.8830\n",
            "Average Precision: 0.6995\n",
            "Training Time: 16.4428 seconds\n",
            "\n",
            "Training XGBoost model with GPU acceleration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:47:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost (GPU) Results ---\n",
            "Confusion Matrix:\n",
            "[[4147  381]\n",
            " [ 612  875]]\n",
            "Accuracy: 0.8349\n",
            "Balanced Accuracy: 0.7521\n",
            "Precision: 0.6967\n",
            "Sensitivity/Recall: 0.5884\n",
            "Specificity: 0.9159\n",
            "F1 Score: 0.6380\n",
            "Matthews Correlation Coefficient: 0.5352\n",
            "AUC-ROC: 0.8889\n",
            "Average Precision: 0.7140\n",
            "Training Time: 0.4348 seconds\n",
            "Prediction Time: 0.0197 seconds\n",
            "\n",
            "Training Random Forest model...\n",
            "\n",
            "--- Random Forest Results ---\n",
            "Confusion Matrix:\n",
            "[[4260  268]\n",
            " [ 774  713]]\n",
            "Accuracy: 0.8268\n",
            "Balanced Accuracy: 0.7102\n",
            "Precision: 0.7268\n",
            "Sensitivity/Recall: 0.4795\n",
            "Specificity: 0.9408\n",
            "F1 Score: 0.5778\n",
            "Matthews Correlation Coefficient: 0.4908\n",
            "AUC-ROC: 0.8789\n",
            "Average Precision: 0.6973\n",
            "Training Time: 0.9476 seconds\n",
            "Prediction Time: 0.0875 seconds\n",
            "\n",
            "Training Logistic Regression model...\n",
            "\n",
            "--- Logistic Regression Results ---\n",
            "Confusion Matrix:\n",
            "[[4136  392]\n",
            " [ 660  827]]\n",
            "Accuracy: 0.8251\n",
            "Balanced Accuracy: 0.7348\n",
            "Precision: 0.6784\n",
            "Sensitivity/Recall: 0.5562\n",
            "Specificity: 0.9134\n",
            "F1 Score: 0.6112\n",
            "Matthews Correlation Coefficient: 0.5039\n",
            "AUC-ROC: 0.8762\n",
            "Average Precision: 0.6758\n",
            "Training Time: 1.8368 seconds\n",
            "Prediction Time: 0.0066 seconds\n",
            "\n",
            "Training Lasso Regression model...\n",
            "\n",
            "--- Lasso Regression Results ---\n",
            "Confusion Matrix:\n",
            "[[4528    0]\n",
            " [1487    0]]\n",
            "Accuracy: 0.7528\n",
            "Balanced Accuracy: 0.5000\n",
            "Precision: 0.0000\n",
            "Sensitivity/Recall: 0.0000\n",
            "Specificity: 1.0000\n",
            "F1 Score: 0.0000\n",
            "Matthews Correlation Coefficient: 0.0000\n",
            "AUC-ROC: 0.7486\n",
            "Average Precision: 0.4989\n",
            "Training Time: 0.0837 seconds\n",
            "Prediction Time: 0.0082 seconds\n",
            "\n",
            "Training Ridge Regression model...\n",
            "\n",
            "--- Ridge Regression Results ---\n",
            "Confusion Matrix:\n",
            "[[4185  343]\n",
            " [ 707  780]]\n",
            "Accuracy: 0.8254\n",
            "Balanced Accuracy: 0.7244\n",
            "Precision: 0.6946\n",
            "Sensitivity/Recall: 0.5245\n",
            "Specificity: 0.9242\n",
            "F1 Score: 0.5977\n",
            "Matthews Correlation Coefficient: 0.4968\n",
            "AUC-ROC: 0.8692\n",
            "Average Precision: 0.6707\n",
            "Training Time: 0.5050 seconds\n",
            "Prediction Time: 0.0024 seconds\n",
            "\n",
            "Training CART Decision Tree model...\n",
            "\n",
            "--- CART Decision Tree Results ---\n",
            "Confusion Matrix:\n",
            "[[4074  454]\n",
            " [ 603  884]]\n",
            "Accuracy: 0.8243\n",
            "Balanced Accuracy: 0.7471\n",
            "Precision: 0.6607\n",
            "Sensitivity/Recall: 0.5945\n",
            "Specificity: 0.8997\n",
            "F1 Score: 0.6258\n",
            "Matthews Correlation Coefficient: 0.5126\n",
            "AUC-ROC: 0.8460\n",
            "Average Precision: 0.6204\n",
            "Training Time: 0.1609 seconds\n",
            "Prediction Time: 0.0036 seconds\n",
            "\n",
            "Training SVM model...\n",
            "\n",
            "--- SVM Results ---\n",
            "Confusion Matrix:\n",
            "[[4188  340]\n",
            " [ 669  818]]\n",
            "Accuracy: 0.8323\n",
            "Balanced Accuracy: 0.7375\n",
            "Precision: 0.7064\n",
            "Sensitivity/Recall: 0.5501\n",
            "Specificity: 0.9249\n",
            "F1 Score: 0.6185\n",
            "Matthews Correlation Coefficient: 0.5197\n",
            "AUC-ROC: 0.8684\n",
            "Average Precision: 0.6965\n",
            "Training Time: 131.2318 seconds\n",
            "Prediction Time: 11.9804 seconds\n",
            "\n",
            "--- Model Comparison ---\n",
            "                      Model  Accuracy  Balanced Accuracy  Precision  \\\n",
            "0  Neural Network (PyTorch)  0.829260           0.757649   0.667638   \n",
            "1             XGBoost (GPU)  0.834913           0.752145   0.696656   \n",
            "2             Random Forest  0.826766           0.710151   0.726809   \n",
            "3       Logistic Regression  0.825104           0.734790   0.678425   \n",
            "4          Lasso Regression  0.752785           0.500000   0.000000   \n",
            "5          Ridge Regression  0.825436           0.724398   0.694568   \n",
            "6        CART Decision Tree  0.824273           0.747110   0.660688   \n",
            "7                       SVM  0.832253           0.737506   0.706390   \n",
            "\n",
            "   Sensitivity  Specificity  F1 Score       MCC   AUC-ROC        AP  \\\n",
            "0     0.616005     0.899293  0.640783  0.529775  0.883001  0.699466   \n",
            "1     0.588433     0.915857  0.637988  0.535225  0.888916  0.713998   \n",
            "2     0.479489     0.940813  0.577796  0.490771  0.878886  0.697252   \n",
            "3     0.556153     0.913428  0.611234  0.503939  0.876194  0.675806   \n",
            "4     0.000000     1.000000  0.000000  0.000000  0.748606  0.498937   \n",
            "5     0.524546     0.924249  0.597701  0.496848  0.869196  0.670735   \n",
            "6     0.594486     0.899735  0.625841  0.512646  0.846047  0.620383   \n",
            "7     0.550101     0.924912  0.618526  0.519727  0.868421  0.696463   \n",
            "\n",
            "   Training Time  Prediction Time  \n",
            "0      16.442813              NaN  \n",
            "1       0.434837         0.019701  \n",
            "2       0.947586         0.087451  \n",
            "3       1.836752         0.006579  \n",
            "4       0.083670         0.008150  \n",
            "5       0.505021         0.002376  \n",
            "6       0.160927         0.003600  \n",
            "7     131.231810        11.980417  \n",
            "Visualization saved to /content/drive/MyDrive/Colab Notebooks/enhanced_model_comparison.png\n",
            "\n",
            "--- Best Models by Metric ---\n",
            "Best model based on Accuracy: XGBoost (GPU) with Accuracy 0.8349\n",
            "Best model based on Balanced Accuracy: Neural Network (PyTorch) with Balanced Accuracy 0.7576\n",
            "Best model based on Precision: Random Forest with Precision 0.7268\n",
            "Best model based on Sensitivity: Neural Network (PyTorch) with Sensitivity 0.6160\n",
            "Best model based on Specificity: Lasso Regression with Specificity 1.0000\n",
            "Best model based on F1 Score: Neural Network (PyTorch) with F1 Score 0.6408\n",
            "Best model based on MCC: XGBoost (GPU) with MCC 0.5352\n",
            "\n",
            "OVERALL BEST MODEL: Neural Network (PyTorch)\n",
            "  Accuracy: 0.8293\n",
            "  Balanced Accuracy: 0.7576\n",
            "  Precision: 0.6676\n",
            "  Sensitivity: 0.6160\n",
            "  Specificity: 0.8993\n",
            "  F1 Score: 0.6408\n",
            "  MCC: 0.5298\n"
          ]
        }
      ]
    }
  ]
}